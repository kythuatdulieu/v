# ‚úÖ FAIRNESS CHECKLIST - Feature Engineering

## üìã 7 ƒêi·ªÉm Ki·ªÉm Tra C√¥ng B·∫±ng

### ‚úÖ 1. Chia theo th·ªùi gian, kh√¥ng random
**Status:** PASS ‚úÖ

**Implementation:**
- Train/test split: 80/20
- Kh√¥ng c√≥ random shuffle
- Duy tr√¨ th·ª© t·ª± th·ªùi gian

**Code location:** `notebooks/01_data_cleaning_and_eda.ipynb`

---

### ‚úÖ 2. Embargo period ƒë·ªÉ tr√°nh ch·ªìng l·∫•n train/test
**Status:** PASS ‚úÖ

**Implementation:**
- **Embargo:** 1 ng√†y = 8 intervals
- **Timeline:** `[Features: N days] ‚Üí [Embargo: 1 day] ‚Üí [Target at day M]`
- Features k·∫øt th√∫c TR∆Ø·ªöC embargo
- Target b·∫Øt ƒë·∫ßu SAU embargo

**Code:**
```python
embargo_intervals = EMBARGO_DAYS * INTERVALS_PER_DAY  # = 1 * 8 = 8 intervals

# XGBoost & LSTM ƒë·ªÅu b·∫Øt ƒë·∫ßu t·ª´:
for i in range(N_intervals + embargo_intervals, len(data) - M_intervals + 1):
    # Features: t·ª´ (i - embargo - N) ƒë·∫øn (i - embargo)
    # Target: t·∫°i (i + M - 1)
```

**L·ª£i √≠ch:**
- Kh√¥ng data leakage
- M√¥ ph·ªèng real-world deployment (c·∫ßn 1 ng√†y ƒë·ªÉ thu th·∫≠p data)

---

### ‚úÖ 3. C√πng m·ª•c ti√™u cho XGB v√† LSTM
**Status:** PASS ‚úÖ

**Implementation:**
- **Target type:** Single value (1 s·ªë duy nh·∫•t)
- **Target location:** Ng√†y th·ª© N + EMBARGO + M
- **KH√îNG ph·∫£i:** Mean, sequence, ho·∫∑c b·∫•t k·ª≥ aggregation n√†o

**XGBoost:**
```python
target_idx = i + M_intervals - 1
y_val = data_sorted.iloc[target_idx][target_col]
```

**LSTM:**
```python
target_idx = i + M_intervals - 1  # GI·ªêNG XGBoost
y_seq = data_sorted.iloc[target_idx][target_col]  # Single value
```

**Verification:**
```python
# y_train_xgb.shape = (samples,)
# y_train_lstm.shape = (samples,)  ‚Üê GI·ªêNG NHAU
```

---

### ‚úÖ 4. Scaler/encoder fit tr√™n train, √°p l√™n test
**Status:** PASS ‚úÖ

**Implementation:**
```python
scaler = StandardScaler()

# Fit ONLY on train
train_features_scaled = scaler.fit_transform(train_data[feature_cols_xgb])

# Transform test (NO FIT)
test_features_scaled = scaler.transform(test_data[feature_cols_xgb])
```

**L∆∞u √Ω:**
- Target KH√îNG scale t·∫°i feature engineering
- LSTM s·∫Ω scale target ri√™ng trong `lstm_trainer.py`
- XGBoost kh√¥ng c·∫ßn scale target (tree-based)

---

### ‚úÖ 5. Kh√¥ng d√πng ƒë·∫∑c tr∆∞ng c√≥ y·∫øu t·ªë t∆∞∆°ng lai
**Status:** PASS ‚úÖ

**Removed features:**
- `WL_Change`: ƒê∆∞·ª£c t√≠nh t·ª´ future - past ‚Üí c√≥ leak
- `month`: C√≥ th·ªÉ leak temporal information

**Retained features:**
```python
feature_cols_xgb = [col for col in train_data.columns 
                    if col not in ['datetime', 'month'] 
                    and 'WL_Change' not in col]
```

**Final features:**
- Water Level: Can Tho, Chau Doc, Dai Ngai
- Rainfall: Can Tho, Chau Doc, Dai Ngai
- **Total: 6 features** (c√¥ng b·∫±ng cho c·∫£ XGB v√† LSTM)

---

### ‚úÖ 6. S·ª≠a target_col th√†nh parameter
**Status:** PASS ‚úÖ

**Before:**
```python
def save_data(...):
    # target_col l√† global variable ‚ùå
    metadata = {
        'target_col': target_col  # L·∫•y t·ª´ global scope
    }
```

**After:**
```python
def save_data(..., target_col, ...):  # ‚úÖ Parameter
    metadata = {
        'target_col': target_col  # L·∫•y t·ª´ parameter
    }
```

**Benefits:**
- Kh√¥ng ph·ª• thu·ªôc global state
- Reusable function
- Clear function signature

---

### ‚úÖ 7. Nh·∫•t qu√°n ƒë∆°n v·ªã interval v√† nh√£n c·ªôt
**Status:** PASS ‚úÖ

**Configuration:**
```python
INTERVAL_HOURS = 3        # 3 gi·ªù/interval
INTERVALS_PER_DAY = 8     # 24 / 3 = 8
EMBARGO_DAYS = 1          # 1 ng√†y = 8 intervals
```

**Data verification:**
```csv
datetime
2022-03-12 06:00:00  ‚Üê 6h
2022-03-12 09:00:00  ‚Üê 9h (+ 3 gi·ªù)
2022-03-12 12:00:00  ‚Üê 12h (+ 3 gi·ªù)
2022-03-12 15:00:00  ‚Üê 15h (+ 3 gi·ªù)
```

**Lag column naming:**
```python
lag_hours = lag * INTERVAL_HOURS  # lag=1 ‚Üí 3h, lag=2 ‚Üí 6h, ...
column_name = f"{col}_lag_{lag_hours}h"
```

**Examples:**
- `Can Tho_Water Level_lag_3h` ‚Üí 3 gi·ªù tr∆∞·ªõc
- `Can Tho_Water Level_lag_6h` ‚Üí 6 gi·ªù tr∆∞·ªõc
- `Can Tho_Water Level_lag_168h` ‚Üí 7 ng√†y tr∆∞·ªõc (7*24=168h)

**Consistency check:**
- ‚úÖ XGBoost: N*8 intervals
- ‚úÖ LSTM: N*8 timesteps
- ‚úÖ Embargo: 1*8 = 8 intervals
- ‚úÖ All labels use correct hour units

---

## üéØ Expected Information Parity

### C√¥ng th·ª©c t·ªïng qu√°t:
```
Total information = N days √ó INTERVALS_PER_DAY √ó num_features
                  = N √ó 8 √ó 6
```

### Cho m·ªói experiment:

| Config | N | Total Intervals | Total Features (XGB) | LSTM Shape |
|--------|---|-----------------|---------------------|------------|
| 7n_1n | 7 | 56 | 56 √ó 6 = 336 | (56, 6) |
| 30n_1n | 30 | 240 | 240 √ó 6 = 1440 | (240, 6) |
| 30n_7n | 30 | 240 | 240 √ó 6 = 1440 | (240, 6) |
| 30n_30n | 30 | 240 | 240 √ó 6 = 1440 | (240, 6) |
| 90n_7n | 90 | 720 | 720 √ó 6 = 4320 | (720, 6) |
| 90n_30n | 90 | 720 | 720 √ó 6 = 4320 | (720, 6) |

**‚úÖ XGBoost v√† LSTM c√≥ C√ôNG l∆∞·ª£ng th√¥ng tin!**

---

## üìä Verification Steps

### 1. Ki·ªÉm tra target shape
```python
assert y_train_xgb.shape == y_train_lstm.shape
assert len(y_train_xgb.shape) == 1  # 1D array
```

### 2. Ki·ªÉm tra feature count
```python
# XGBoost
assert X_train_xgb.shape[1] == N * INTERVALS_PER_DAY * num_features

# LSTM
assert X_train_lstm.shape[1] == N * INTERVALS_PER_DAY
assert X_train_lstm.shape[2] == num_features
```

### 3. Ki·ªÉm tra embargo
```python
# Datetime c·ªßa target ph·∫£i c√°ch datetime cu·ªëi c·ªßa features >= 1 ng√†y
assert (target_datetime - feature_end_datetime).days >= EMBARGO_DAYS
```

### 4. Ki·ªÉm tra no data leakage
```python
# Test set kh√¥ng overlap v·ªõi train set
assert train_data['datetime'].max() < test_data['datetime'].min()
```

---

## üöÄ Run Notebook

ƒê·ªÉ t·∫°o l·∫°i to√†n b·ªô data:

```bash
cd notebooks
# Run notebook 02_feature_engineering.ipynb
# ‚Üí Nh·∫•n "Run All" l√† xong!
```

**Output:**
- `../data/{config}_xgb/` - XGBoost data (CSV)
- `../data/{config}_lstm/` - LSTM data (NPY)
- `../data/data_summary.csv` - T√≥ng k·∫øt
- `../models/scalers/feature_scaler.pkl` - Scaler

---

## ‚úÖ Final Checklist Summary

| # | Criterion | Status | Impact |
|---|-----------|--------|---------|
| 1 | Time-based split | ‚úÖ PASS | No future leak |
| 2 | Embargo period | ‚úÖ PASS | No overlap |
| 3 | Same target | ‚úÖ PASS | Fair comparison |
| 4 | Scaler on train | ‚úÖ PASS | No test leak |
| 5 | No future features | ‚úÖ PASS | Valid features |
| 6 | target_col param | ‚úÖ PASS | Clean code |
| 7 | Interval consistency | ‚úÖ PASS | Correct labels |

**Overall Score: 7/7 PASS** ‚úÖ

---

## üìù Notes

### V·ªÅ interval size:
- Data hi·ªán t·∫°i: **3-hour intervals** (6h, 9h, 12h, ...)
- N·∫øu data l√† 15-min intervals:
  - Change `INTERVAL_HOURS = 0.25`
  - Change `INTERVALS_PER_DAY = 96`
  - Update lag labels accordingly

### V·ªÅ target:
- Hi·ªán t·∫°i: **Single value** t·∫°i ng√†y N+EMBARGO+M
- ƒê√¢y l√† c√°ch C√îNG B·∫∞NG nh·∫•t ƒë·ªÉ so s√°nh XGB vs LSTM
- N·∫øu c·∫ßn predict sequence, ph·∫£i training ri√™ng (kh√¥ng so s√°nh tr·ª±c ti·∫øp ƒë∆∞·ª£c)

### V·ªÅ features:
- XGBoost: Flattened lag features (tabular)
- LSTM: Sequences (3D tensor)
- **C√πng th√¥ng tin**, ch·ªâ kh√°c format

---

**Last updated:** 2025-10-04  
**Verified by:** Feature Engineering Pipeline v2.0
