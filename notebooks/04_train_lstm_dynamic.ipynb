{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LSTM Model - Dynamic Configuration\n",
    "\n",
    "## M·ª•c ti√™u\n",
    "Notebook training LSTM ƒë·ªông c√≥ th·ªÉ ch·∫°y cho b·∫•t k·ª≥ configuration n√†o trong EXPERIMENTS.\n",
    "Ch·ªâ c·∫ßn thay ƒë·ªïi CONFIG_NAME ·ªü cell ƒë·∫ßu ti√™n ƒë·ªÉ train configuration kh√°c.\n",
    "\n",
    "## C√°ch s·ª≠ d·ª•ng\n",
    "1. Ch·ªçn CONFIG_NAME t·ª´ danh s√°ch: '7n_1n', '30n_1n', '30n_7n', '30n_30n', '90n_7n', '90n_30n'\n",
    "2. Run all cells\n",
    "3. K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u t·ª± ƒë·ªông theo configuration\n",
    "\n",
    "## Troubleshooting\n",
    "- **LSTM fails**: Install TensorFlow v·ªõi `pip install tensorflow`\n",
    "- **Memory issues**: Gi·∫£m batch_size trong LSTM_PARAMS\n",
    "- **Long training time**: Gi·∫£m epochs ho·∫∑c patience trong LSTM_PARAMS\n",
    "- **Overfitting**: TƒÉng dropout ho·∫∑c patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# CONFIGURATION - THAY ƒê·ªîI T·∫†I ƒê√ÇY\n",
    "# ===============================================\n",
    "CONFIG_NAME = '90n_30n'  # Thay ƒë·ªïi theo experiment mu·ªën ch·∫°y\n",
    "\n",
    "# Available configurations:\n",
    "# '7n_1n'    : 7 days ‚Üí 1 day\n",
    "# '30n_1n'   : 30 days ‚Üí 1 day  \n",
    "# '30n_7n'   : 30 days ‚Üí 7 days\n",
    "# '30n_30n'  : 30 days ‚Üí 30 days\n",
    "# '90n_7n'   : 90 days ‚Üí 7 days\n",
    "# '90n_30n'  : 90 days ‚Üí 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "\n",
    "# Enhanced TensorFlow availability check from notebook 05\n",
    "TF_AVAILABLE = False\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    TF_AVAILABLE = True\n",
    "    print(f\"‚úÖ TensorFlow {tf.__version__} available\")\n",
    "    \n",
    "    # Check for GPU\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(f\"üöÄ GPU acceleration available\")\n",
    "    else:\n",
    "        print(f\"üíª Using CPU for training\")\n",
    "        \n",
    "    # Import LSTM trainer\n",
    "    from lstm_trainer import train_lstm_model\n",
    "    \n",
    "    # Force reload config module to pick up changes\n",
    "    import config\n",
    "    importlib.reload(config)\n",
    "    from config import EXPERIMENTS, LSTM_PARAMS, RANDOM_SEED\n",
    "    \n",
    "    # Reload the module to pick up any changes\n",
    "    import lstm_trainer\n",
    "    importlib.reload(lstm_trainer)\n",
    "    from lstm_trainer import train_lstm_model\n",
    "    \n",
    "    print(f\"‚úÖ LSTM trainer imported successfully\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå TensorFlow not available: {e}\")\n",
    "    print(f\"‚ö†Ô∏è LSTM training will fail\")\n",
    "    print(\"üí° Please install TensorFlow: pip install tensorflow\")\n",
    "    raise ImportError(\"TensorFlow required for LSTM training\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if TF_AVAILABLE:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Validate configuration\n",
    "if CONFIG_NAME not in EXPERIMENTS:\n",
    "    raise ValueError(f\"Invalid CONFIG_NAME: {CONFIG_NAME}. Available: {list(EXPERIMENTS.keys())}\")\n",
    "\n",
    "# Get experiment configuration\n",
    "experiment_config = EXPERIMENTS[CONFIG_NAME]\n",
    "N_DAYS = experiment_config['N']\n",
    "M_DAYS = experiment_config['M']\n",
    "DESCRIPTION = experiment_config['description']\n",
    "\n",
    "print(f\"‚úÖ Configuration loaded: {CONFIG_NAME}\")\n",
    "print(f\"üìä Experiment: {DESCRIPTION}\")\n",
    "print(f\"üì• Input: {N_DAYS} days\")\n",
    "print(f\"üì§ Output: {M_DAYS} days\")\n",
    "print(f\"üé≤ Random seed: {RANDOM_SEED}\")\n",
    "print(f\"‚è∞ Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üîÑ Config and LSTM trainer modules reloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration-Specific Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'LSTM'\n",
    "\n",
    "print(f\"=== TRAINING {MODEL_TYPE} MODEL: {CONFIG_NAME} ===\")\n",
    "print(f\"C·∫•u h√¨nh: {N_DAYS} ng√†y sequence ‚Üí {M_DAYS} ng√†y d·ª± ƒëo√°n\")\n",
    "print(f\"M√¥ t·∫£: {DESCRIPTION}\")\n",
    "print(f\"Target: M·ª±c n∆∞·ªõc C·∫ßn Th∆°\")\n",
    "print(f\"Model: {MODEL_TYPE} v·ªõi sequence input\")\n",
    "\n",
    "# Expected data characteristics\n",
    "features_per_interval = 6  # 3 stations * 2 parameters\n",
    "timesteps = N_DAYS\n",
    "\n",
    "print(f\"\\nExpected data characteristics:\")\n",
    "print(f\"  Input shape: (samples, {timesteps}, {features_per_interval})\")\n",
    "print(f\"  - Timesteps: {timesteps} ( {8 * N_DAYS} points)\")\n",
    "print(f\"  - Features: {features_per_interval} (3 stations √ó 2 parameters)\")\n",
    "print(f\"  Output type: {'Single value' if M_DAYS == 1 else f'Aggregated over {M_DAYS} days'}\")\n",
    "\n",
    "print(f\"\\nGrid search parameters:\")\n",
    "for param, values in LSTM_PARAMS.items():\n",
    "    if isinstance(values, list):\n",
    "        print(f\"  {param}: {values}\")\n",
    "    else:\n",
    "        print(f\"  {param}: {values}\")\n",
    "        \n",
    "param_combinations = np.prod([len(v) for v in LSTM_PARAMS.values() if isinstance(v, list)])\n",
    "print(f\"\\nTotal hyperparameter combinations: {param_combinations}\")\n",
    "print(f\"Max epochs per combination: {LSTM_PARAMS['epochs']}\")\n",
    "print(f\"Early stopping patience: {LSTM_PARAMS['patience']}\")\n",
    "\n",
    "# Warning about LSTM challenges based on notebook 05 analysis\n",
    "print(f\"\\n‚ö†Ô∏è  LSTM Training Considerations:\")\n",
    "print(f\"   ‚Ä¢ LSTM models are prone to overfitting on small datasets\")\n",
    "print(f\"   ‚Ä¢ Current config may need tuning (epochs={LSTM_PARAMS['epochs']}, patience={LSTM_PARAMS['patience']})\")\n",
    "print(f\"   ‚Ä¢ Consider increasing validation_split if performance is poor\")\n",
    "print(f\"   ‚Ä¢ Monitor train vs validation loss closely\")\n",
    "print(f\"   ‚Ä¢ Expected training time: {param_combinations * 2:.0f}-{param_combinations * 5:.0f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ki·ªÉm tra d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced data validation from notebook 05\n",
    "data_folder = '../data'\n",
    "config_folder = f\"{data_folder}/{CONFIG_NAME}_lstm\"\n",
    "\n",
    "print(f\"üîç Checking LSTM data availability for {CONFIG_NAME}...\")\n",
    "\n",
    "def validate_lstm_data_for_config():\n",
    "    \"\"\"Validate LSTM data availability for the selected configuration\"\"\"\n",
    "    if not os.path.exists(config_folder):\n",
    "        return False, f\"LSTM data folder does not exist: {config_folder}\"\n",
    "    \n",
    "    # Check required files\n",
    "    required_files = ['X_train.npy', 'X_test.npy', 'y_train.npy', 'y_test.npy', 'metadata.json']\n",
    "    missing_files = []\n",
    "    \n",
    "    for file in required_files:\n",
    "        file_path = f\"{config_folder}/{file}\"\n",
    "        if not os.path.exists(file_path):\n",
    "            missing_files.append(file)\n",
    "    \n",
    "    if missing_files:\n",
    "        return False, f\"Missing LSTM files: {missing_files}\"\n",
    "    \n",
    "    return True, \"All LSTM data files available\"\n",
    "\n",
    "# Validate data\n",
    "data_ready, message = validate_lstm_data_for_config()\n",
    "\n",
    "if data_ready:\n",
    "    print(f\"‚úÖ {message}\")\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata_file = f\"{config_folder}/metadata.json\"\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"\\nüìä LSTM Data Information:\")\n",
    "    print(f\"  X_train shape: {metadata['X_train_shape']}\")\n",
    "    print(f\"  X_test shape: {metadata['X_test_shape']}\")\n",
    "    print(f\"  y_train shape: {metadata['y_train_shape']}\")\n",
    "    print(f\"  y_test shape: {metadata['y_test_shape']}\")\n",
    "    print(f\"  Target: {metadata['target_col']}\")\n",
    "    print(f\"  Created: {metadata.get('created_at', 'Unknown')}\")\n",
    "    \n",
    "    # Validate expected vs actual shape\n",
    "    expected_shape = (None, timesteps, features_per_interval)  # None for variable batch size\n",
    "    actual_train_shape = metadata['X_train_shape']\n",
    "    \n",
    "    if len(actual_train_shape) == 3 and actual_train_shape[1:] == expected_shape[1:]:\n",
    "        print(f\"  ‚úÖ Data shape matches expectation: {actual_train_shape}\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Data shape mismatch: expected (?, {timesteps}, {features_per_interval}), got {actual_train_shape}\")\n",
    "        \n",
    "    # Check data size for overfitting warning\n",
    "    n_samples = actual_train_shape[0]\n",
    "    if n_samples < 1000:\n",
    "        print(f\"  ‚ö†Ô∏è  Small dataset ({n_samples} samples) - high overfitting risk!\")\n",
    "    elif n_samples < 2000:\n",
    "        print(f\"  ‚ö†Ô∏è  Medium dataset ({n_samples} samples) - monitor overfitting\")\n",
    "    else:\n",
    "        print(f\"  ‚úÖ Good dataset size ({n_samples} samples)\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå {message}\")\n",
    "    print(f\"üí° Please run notebook 02_feature_engineering.ipynb first\")\n",
    "    raise RuntimeError(f\"LSTM data not ready for {CONFIG_NAME}\")\n",
    "\n",
    "# Check if model already exists\n",
    "model_folder = f\"../models/{CONFIG_NAME}_lstm\"\n",
    "model_file = f\"{model_folder}/best_model.keras\"\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    print(f\"\\n‚ö†Ô∏è  LSTM model already exists: {model_file}\")\n",
    "    print(f\"üîÑ Training will overwrite existing model.\")\n",
    "else:\n",
    "    print(f\"\\nüÜï Training new LSTM model for {CONFIG_NAME}\")\n",
    "\n",
    "print(f\"\\nüéØ Ready to start LSTM training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training v·ªõi Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced LSTM training with better error handling from notebook 05\n",
    "# Extract epochs and patience from param_grid like in notebook 05\n",
    "epochs = LSTM_PARAMS.get('epochs', [100])[0] if isinstance(LSTM_PARAMS.get('epochs', [100]), list) else LSTM_PARAMS.get('epochs', 100)\n",
    "patience = LSTM_PARAMS.get('patience', [5])[0] if isinstance(LSTM_PARAMS.get('patience', [5]), list) else LSTM_PARAMS.get('patience', 5)\n",
    "\n",
    "# Prepare parameter grid (remove epochs and patience)\n",
    "lstm_param_grid = LSTM_PARAMS.copy()\n",
    "lstm_param_grid.pop('epochs', None)\n",
    "lstm_param_grid.pop('patience', None)\n",
    "\n",
    "print(f\"\\nüöÄ Starting LSTM training for {CONFIG_NAME}...\")\n",
    "print(f\"üìä Experiment: {DESCRIPTION}\")\n",
    "print(f\"üî¢ Parameter combinations: {param_combinations}\")\n",
    "print(f\"üìà Epochs per combination: {epochs}\")\n",
    "print(f\"‚è≥ Early stopping patience: {patience}\")\n",
    "print(f\"‚è∞ Expected training time: {param_combinations * 3:.0f}-{param_combinations * 8:.0f} minutes\")\n",
    "print(f\"üéØ Parameters: {lstm_param_grid}\")\n",
    "\n",
    "# GPU optimization for small datasets\n",
    "print(f\"\\n‚ö° GPU Optimization for small dataset:\")\n",
    "n_samples = 914  # From data loading output\n",
    "if n_samples < 2000:\n",
    "    print(f\"  üìä Small dataset detected ({n_samples} samples)\")\n",
    "    print(f\"  üîß Optimizing for fast training...\")\n",
    "    \n",
    "    # Reduce epochs for small datasets (faster convergence expected)\n",
    "    if epochs > 30:\n",
    "        epochs = min(30, epochs)\n",
    "        print(f\"  üìâ Reduced max epochs to {epochs} (small dataset converges faster)\")\n",
    "    \n",
    "    # Increase patience slightly to avoid premature stopping\n",
    "    if patience < 7:\n",
    "        patience = 7\n",
    "        print(f\"  ‚è±Ô∏è Increased patience to {patience} (avoid early stopping)\")\n",
    "    \n",
    "    # Prefer larger batch sizes for GPU efficiency\n",
    "    if 'batch_size' in lstm_param_grid:\n",
    "        original_batches = lstm_param_grid['batch_size']\n",
    "        lstm_param_grid['batch_size'] = [b for b in original_batches if b >= 32]\n",
    "        if not lstm_param_grid['batch_size']:  # If all filtered out\n",
    "            lstm_param_grid['batch_size'] = [32]\n",
    "        print(f\"  üöÄ Optimized batch sizes: {lstm_param_grid['batch_size']} (GPU efficiency)\")\n",
    "    \n",
    "    # Reduce model complexity for small datasets\n",
    "    if 'units' in lstm_param_grid:\n",
    "        original_units = lstm_param_grid['units']\n",
    "        lstm_param_grid['units'] = [u for u in original_units if u <= 100]\n",
    "        if not lstm_param_grid['units']:\n",
    "            lstm_param_grid['units'] = [50, 100]\n",
    "        print(f\"  üß† Reduced LSTM units: {lstm_param_grid['units']} (prevent overfitting)\")\n",
    "\n",
    "# Memory management for large sequences\n",
    "timesteps = N_DAYS\n",
    "if timesteps > 2000:  # Very long sequences\n",
    "    print(f\"\\n‚ö†Ô∏è  Long sequence detected ({timesteps} timesteps)\")\n",
    "    print(f\"Consider reducing batch sizes if memory issues occur\")\n",
    "    # Reduce batch sizes for memory efficiency\n",
    "    if 'batch_size' in lstm_param_grid:\n",
    "        lstm_param_grid['batch_size'] = [b for b in lstm_param_grid['batch_size'] if b <= 32]\n",
    "        print(f\"Adjusted batch sizes: {lstm_param_grid['batch_size']}\")\n",
    "\n",
    "# Update param combinations after optimization\n",
    "optimized_combinations = np.prod([len(v) for v in lstm_param_grid.values() if isinstance(v, list)])\n",
    "print(f\"\\nüéØ Optimized training plan:\")\n",
    "print(f\"  Original combinations: {param_combinations}\")\n",
    "print(f\"  Optimized combinations: {optimized_combinations}\")\n",
    "print(f\"  Max epochs: {epochs}\")\n",
    "print(f\"  Expected time: {optimized_combinations * 1:.0f}-{optimized_combinations * 3:.0f} minutes\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüìä Starting LSTM grid search...\")\n",
    "    print(f\"‚ö†Ô∏è  Note: LSTM models may overfit on small datasets\")\n",
    "    \n",
    "    trainer = train_lstm_model(\n",
    "        config_name=CONFIG_NAME,\n",
    "        param_grid=lstm_param_grid,  # Pass grid without epochs/patience\n",
    "        data_folder='../data',\n",
    "        models_folder='../models',\n",
    "        epochs=epochs,  # Pass as separate parameter\n",
    "        patience=patience,  # Pass as separate parameter\n",
    "        validation_split=0.2,\n",
    "        verbose=0  # Reduce verbosity for faster training\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ Training completed in {training_time/60:.1f} minutes\")\n",
    "    print(f\"‚ö° Speed: {training_time/optimized_combinations:.1f} seconds per combination\")\n",
    "    \n",
    "except Exception as e:\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n‚ùå Training failed after {training_time/60:.1f} minutes\")\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "    # Common LSTM training issues and suggestions\n",
    "    if \"memory\" in str(e).lower() or \"oom\" in str(e).lower():\n",
    "        print(f\"\\nüí° Memory issue detected for {CONFIG_NAME}:\")\n",
    "        print(f\"  - Try reducing batch_size in config.py\")\n",
    "        print(f\"  - Consider reducing LSTM units\")\n",
    "        print(f\"  - Current sequence length: {timesteps} (very long for {N_DAYS} days)\")\n",
    "    elif \"shape\" in str(e).lower():\n",
    "        print(f\"\\nüí° Shape mismatch detected:\")\n",
    "        print(f\"  - Check feature engineering output for {CONFIG_NAME}\")\n",
    "        print(f\"  - Verify data preprocessing steps\")\n",
    "    \n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ph√¢n t√≠ch k·∫øt qu·∫£ theo Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load v√† hi·ªÉn th·ªã k·∫øt qu·∫£ chi ti·∫øt\n",
    "results_folder = f\"../models/{CONFIG_NAME}_lstm\"\n",
    "\n",
    "# Load results\n",
    "with open(f\"{results_folder}/results.json\", 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(f\"=== K·∫æT QU·∫¢ TRAINING {CONFIG_NAME} ===\")\n",
    "print(f\"Configuration: {DESCRIPTION}\")\n",
    "print(f\"Model type: {results['model_type']}\")\n",
    "\n",
    "print(f\"\\nBest hyperparameters:\")\n",
    "for param, value in results['best_params'].items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest validation loss: {results['best_val_loss']:.6f}\")\n",
    "print(f\"Training epochs: {results['training_epochs']}\")\n",
    "\n",
    "print(f\"\\nTraining metrics:\")\n",
    "for metric, value in results['train_metrics'].items():\n",
    "    print(f\"  {metric}: {value:.6f}\")\n",
    "\n",
    "print(f\"\\nTest metrics:\")\n",
    "for metric, value in results['test_metrics'].items():\n",
    "    print(f\"  {metric}: {value:.6f}\")\n",
    "\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(f\"  Total parameters: {results['model_params']['total_params']:,}\")\n",
    "print(f\"  Trainable parameters: {results['model_params']['trainable_params']:,}\")\n",
    "print(f\"  Grid search combinations: {results['grid_search_combinations']}\")\n",
    "print(f\"  Data shapes: {results['data_shapes']}\")\n",
    "print(f\"  Training samples: {results['data_shapes']['X_train'][0]:,}\")\n",
    "print(f\"  Test samples: {results['data_shapes']['X_test'][0]:,}\")\n",
    "\n",
    "# Performance interpretation based on configuration\n",
    "rmse = results['test_metrics']['RMSE']\n",
    "r2 = results['test_metrics']['R2']\n",
    "val_loss = results['best_val_loss']\n",
    "\n",
    "print(f\"\\nüìä Performance Assessment cho {CONFIG_NAME}:\")\n",
    "if r2 > 0.95:\n",
    "    performance = \"Excellent (R¬≤ > 0.95)\"\n",
    "elif r2 > 0.90:\n",
    "    performance = \"Very Good (R¬≤ > 0.90)\"\n",
    "elif r2 > 0.80:\n",
    "    performance = \"Good (R¬≤ > 0.80)\"\n",
    "elif r2 > 0.70:\n",
    "    performance = \"Fair (R¬≤ > 0.70)\"\n",
    "else:\n",
    "    performance = \"Needs Improvement (R¬≤ ‚â§ 0.70)\"\n",
    "\n",
    "print(f\"  Overall: {performance}\")\n",
    "print(f\"  RMSE: {rmse:.4f} m (¬±{rmse*100:.1f} cm average error)\")\n",
    "print(f\"  R¬≤: {r2:.4f} ({r2*100:.1f}% variance explained)\")\n",
    "print(f\"  Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "# Configuration-specific insights\n",
    "if M_DAYS == 1:\n",
    "    print(f\"  Short-term prediction (1 day): {'Good for LSTM' if r2 > 0.80 else 'May need more data or tuning'}\")\n",
    "elif M_DAYS <= 7:\n",
    "    print(f\"  Medium-term prediction ({M_DAYS} days): {'LSTM handles well' if r2 > 0.70 else 'Challenging for sequential model'}\")\n",
    "else:\n",
    "    print(f\"  Long-term prediction ({M_DAYS} days): {'Impressive for LSTM' if r2 > 0.60 else 'Expected difficulty for long-term'}\")\n",
    "\n",
    "timesteps = N_DAYS\n",
    "if timesteps >= 2000:\n",
    "    print(f\"  Very long sequences ({timesteps}): {'LSTM captures long patterns well' if r2 > 0.75 else 'May suffer from vanishing gradients'}\")\n",
    "elif timesteps >= 500:\n",
    "    print(f\"  Long sequences ({timesteps}): {'Good for temporal patterns' if r2 > 0.80 else 'Consider shorter sequences'}\")\n",
    "else:\n",
    "    print(f\"  Short sequences ({timesteps}): {'Efficient processing' if r2 > 0.85 else 'May need longer history'}\")\n",
    "\n",
    "# Training efficiency analysis\n",
    "avg_epochs = results['training_epochs']\n",
    "# Handle LSTM_PARAMS['epochs'] which might be a list\n",
    "max_epochs_param = LSTM_PARAMS['epochs']\n",
    "max_epochs = max_epochs_param[0] if isinstance(max_epochs_param, list) else max_epochs_param\n",
    "if avg_epochs < max_epochs * 0.3:\n",
    "    print(f\"  Training efficiency: Early convergence ({avg_epochs}/{max_epochs} epochs)\")\n",
    "elif avg_epochs >= max_epochs * 0.8:\n",
    "    print(f\"  Training efficiency: May need more epochs ({avg_epochs}/{max_epochs})\")\n",
    "else:\n",
    "    print(f\"  Training efficiency: Good convergence ({avg_epochs}/{max_epochs} epochs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grid search results\n",
    "grid_results = pd.read_csv(f\"{results_folder}/grid_search_results_full.csv\")\n",
    "\n",
    "print(f\"=== GRID SEARCH RESULTS - {CONFIG_NAME} ===\")\n",
    "print(f\"Total combinations tested: {len(grid_results)}\")\n",
    "print(f\"Configuration: {DESCRIPTION}\")\n",
    "\n",
    "# Remove failed experiments\n",
    "successful_results = grid_results[grid_results['best_val_loss'] != float('inf')].copy()\n",
    "failed_results = grid_results[grid_results['best_val_loss'] == float('inf')]\n",
    "\n",
    "print(f\"Successful combinations: {len(successful_results)}\")\n",
    "if len(failed_results) > 0:\n",
    "    print(f\"Failed combinations: {len(failed_results)}\")\n",
    "    print(f\"Common failure reasons: {failed_results['error'].value_counts().head(3).to_dict() if 'error' in failed_results.columns else 'Not recorded'}\")\n",
    "\n",
    "if len(successful_results) > 0:\n",
    "    # Top 10 best combinations\n",
    "    top_combinations = successful_results.nsmallest(10, 'best_val_loss')[[\n",
    "        'units', 'n_layers', 'dropout', 'batch_size', 'best_val_loss', 'epochs_trained'\n",
    "    ]]\n",
    "    \n",
    "    print(f\"\\nTop 10 combinations for {CONFIG_NAME} (by validation loss):\")\n",
    "    print(top_combinations.to_string(index=False))\n",
    "    \n",
    "    # Parameter analysis with configuration context\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'Hyperparameter Effects - {CONFIG_NAME} LSTM ({DESCRIPTION})', fontsize=16)\n",
    "    \n",
    "    # Units effect\n",
    "    units_effect = successful_results.groupby('units')['best_val_loss'].agg(['mean', 'std', 'count'])\n",
    "    axes[0,0].errorbar(units_effect.index, units_effect['mean'], yerr=units_effect['std'], \n",
    "                      marker='o', capsize=5)\n",
    "    axes[0,0].set_xlabel('LSTM Units')\n",
    "    axes[0,0].set_ylabel('Validation Loss')\n",
    "    axes[0,0].set_title('Effect of LSTM Units')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Layers effect\n",
    "    layers_effect = successful_results.groupby('n_layers')['best_val_loss'].agg(['mean', 'std', 'count'])\n",
    "    axes[0,1].errorbar(layers_effect.index, layers_effect['mean'], yerr=layers_effect['std'], \n",
    "                      marker='o', capsize=5)\n",
    "    axes[0,1].set_xlabel('Number of LSTM Layers')\n",
    "    axes[0,1].set_ylabel('Validation Loss')\n",
    "    axes[0,1].set_title('Effect of Number of Layers')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Dropout effect\n",
    "    dropout_effect = successful_results.groupby('dropout')['best_val_loss'].agg(['mean', 'std', 'count'])\n",
    "    axes[1,0].errorbar(dropout_effect.index, dropout_effect['mean'], yerr=dropout_effect['std'], \n",
    "                      marker='o', capsize=5)\n",
    "    axes[1,0].set_xlabel('Dropout Rate')\n",
    "    axes[1,0].set_ylabel('Validation Loss')\n",
    "    axes[1,0].set_title('Effect of Dropout')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Batch size effect\n",
    "    batch_effect = successful_results.groupby('batch_size')['best_val_loss'].agg(['mean', 'std', 'count'])\n",
    "    axes[1,1].errorbar(batch_effect.index, batch_effect['mean'], yerr=batch_effect['std'], \n",
    "                      marker='o', capsize=5)\n",
    "    axes[1,1].set_xlabel('Batch Size')\n",
    "    axes[1,1].set_ylabel('Validation Loss')\n",
    "    axes[1,1].set_title('Effect of Batch Size')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Configuration-specific hyperparameter insights\n",
    "    best_params = results['best_params']\n",
    "    print(f\"\\nüîß Hyperparameter insights for {CONFIG_NAME}:\")\n",
    "    \n",
    "    if best_params['units'] >= 120:\n",
    "        print(f\"  - High LSTM units ({best_params['units']}) needed for complex {N_DAYS}‚Üí{M_DAYS} patterns\")\n",
    "    elif best_params['units'] <= 60:\n",
    "        print(f\"  - Low LSTM units ({best_params['units']}) sufficient, good efficiency\")\n",
    "    \n",
    "    if best_params['n_layers'] >= 2:\n",
    "        print(f\"  - Deep LSTM ({best_params['n_layers']} layers) captures hierarchical patterns\")\n",
    "    else:\n",
    "        print(f\"  - Single LSTM layer sufficient for {CONFIG_NAME}\")\n",
    "    \n",
    "    if best_params['dropout'] >= 0.25:\n",
    "        print(f\"  - High dropout ({best_params['dropout']}) prevents overfitting\")\n",
    "    elif best_params['dropout'] <= 0.1:\n",
    "        print(f\"  - Low dropout ({best_params['dropout']}), model generalizes well\")\n",
    "    \n",
    "    if best_params['batch_size'] <= 32:\n",
    "        print(f\"  - Small batch size ({best_params['batch_size']}) for stable training\")\n",
    "    elif best_params['batch_size'] >= 64:\n",
    "        print(f\"  - Large batch size ({best_params['batch_size']}) for efficient training\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ùå No successful grid search results found!\")\n",
    "    print(\"All hyperparameter combinations failed. Check:\")\n",
    "    print(\"- Data format and shapes\")\n",
    "    print(\"- Memory availability\")\n",
    "    print(\"- TensorFlow installation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training history\n",
    "if os.path.exists(f\"{results_folder}/training_history.csv\"):\n",
    "    training_history = pd.read_csv(f\"{results_folder}/training_history.csv\")\n",
    "    \n",
    "    print(f\"=== TRAINING HISTORY - {CONFIG_NAME} ===\")\n",
    "    print(f\"Configuration: {DESCRIPTION}\")\n",
    "    print(f\"Total epochs: {len(training_history)}\")\n",
    "    print(f\"Final training loss: {training_history['loss'].iloc[-1]:.6f}\")\n",
    "    print(f\"Final validation loss: {training_history['val_loss'].iloc[-1]:.6f}\")\n",
    "    print(f\"Best validation loss: {training_history['val_loss'].min():.6f}\")\n",
    "    print(f\"Best epoch: {training_history['val_loss'].idxmin() + 1}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    final_train_loss = training_history['loss'].iloc[-1]\n",
    "    final_val_loss = training_history['val_loss'].iloc[-1]\n",
    "    overfitting_ratio = final_val_loss / final_train_loss\n",
    "    \n",
    "    if overfitting_ratio > 1.5:\n",
    "        print(f\"‚ö†Ô∏è  Potential overfitting detected (val/train loss ratio: {overfitting_ratio:.2f})\")\n",
    "    elif overfitting_ratio < 1.1:\n",
    "        print(f\"‚úÖ Good generalization (val/train loss ratio: {overfitting_ratio:.2f})\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Acceptable generalization (val/train loss ratio: {overfitting_ratio:.2f})\")\n",
    "    \n",
    "    # Plot training history with configuration-specific title\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle(f'Training History - {CONFIG_NAME} ({DESCRIPTION})', fontsize=16)\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0].plot(training_history.index + 1, training_history['loss'], 'b-', label='Training Loss')\n",
    "    axes[0].plot(training_history.index + 1, training_history['val_loss'], 'r-', label='Validation Loss')\n",
    "    axes[0].axvline(training_history['val_loss'].idxmin() + 1, color='green', linestyle='--', \n",
    "                   label=f'Best Epoch ({training_history[\"val_loss\"].idxmin() + 1})')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss (MSE)')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE curves\n",
    "    if 'mae' in training_history.columns:\n",
    "        axes[1].plot(training_history.index + 1, training_history['mae'], 'b-', label='Training MAE')\n",
    "        axes[1].plot(training_history.index + 1, training_history['val_mae'], 'r-', label='Validation MAE')\n",
    "        axes[1].axvline(training_history['val_loss'].idxmin() + 1, color='green', linestyle='--',\n",
    "                       label=f'Best Epoch ({training_history[\"val_loss\"].idxmin() + 1})')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('MAE')\n",
    "        axes[1].set_title('Training and Validation MAE')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Training insights based on configuration\n",
    "    print(f\"\\nüìà Training insights for {CONFIG_NAME}:\")\n",
    "    \n",
    "    convergence_epoch = training_history['val_loss'].idxmin() + 1\n",
    "    total_epochs = len(training_history)\n",
    "    \n",
    "    if convergence_epoch < total_epochs * 0.3:\n",
    "        print(f\"  - Fast convergence (epoch {convergence_epoch}/{total_epochs})\")\n",
    "        print(f\"  - Model learned patterns quickly for {N_DAYS}‚Üí{M_DAYS}\")\n",
    "    elif convergence_epoch > total_epochs * 0.8:\n",
    "        print(f\"  - Slow convergence (epoch {convergence_epoch}/{total_epochs})\")\n",
    "        print(f\"  - Complex {N_DAYS}‚Üí{M_DAYS} pattern requires more training\")\n",
    "    else:\n",
    "        print(f\"  - Normal convergence (epoch {convergence_epoch}/{total_epochs})\")\n",
    "        \n",
    "    # Learning curve analysis\n",
    "    early_loss = training_history['val_loss'].iloc[:5].mean()\n",
    "    final_loss = training_history['val_loss'].iloc[-5:].mean()\n",
    "    improvement = (early_loss - final_loss) / early_loss * 100\n",
    "    \n",
    "    print(f\"  - Validation loss improvement: {improvement:.1f}%\")\n",
    "    if improvement > 50:\n",
    "        print(f\"  - Excellent learning progress\")\n",
    "    elif improvement > 20:\n",
    "        print(f\"  - Good learning progress\")\n",
    "    else:\n",
    "        print(f\"  - Limited improvement, may need different architecture\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Training history not found: {results_folder}/training_history.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Predictions Visualization i√ßin Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model v√† d·ª± ƒëo√°n\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Handle Keras serialization issues\n",
    "try:\n",
    "    # Try loading with compile=False to avoid metric issues\n",
    "    model = load_model(f\"{results_folder}/best_model.h5\", compile=False)\n",
    "    \n",
    "    # Recompile the model with standard metrics\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    print(\"‚úÖ Model loaded successfully (recompiled)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    # If loading fails, try with custom objects\n",
    "    try:\n",
    "        custom_objects = {\n",
    "            'mse': tf.keras.metrics.MeanSquaredError(),\n",
    "            'mae': tf.keras.metrics.MeanAbsoluteError()\n",
    "        }\n",
    "        model = load_model(f\"{results_folder}/best_model.h5\", custom_objects=custom_objects)\n",
    "        print(\"‚úÖ Model loaded with custom objects\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Failed to load model: {e2}\")\n",
    "        raise e2\n",
    "\n",
    "print(f\"=== MODEL ARCHITECTURE - {CONFIG_NAME} ===\")\n",
    "print(f\"Configuration: {DESCRIPTION}\")\n",
    "model.summary()\n",
    "\n",
    "# Load test data\n",
    "X_test = np.load(f\"../data/{CONFIG_NAME}_lstm/X_test.npy\")\n",
    "y_test = np.load(f\"../data/{CONFIG_NAME}_lstm/y_test.npy\")\n",
    "datetime_test = pd.read_csv(f\"../data/{CONFIG_NAME}_lstm/datetime_test.csv\")\n",
    "datetime_test['datetime'] = datetime_test['0']\n",
    "datetime_test['datetime'] = pd.to_datetime(datetime_test['datetime'])\n",
    "\n",
    "# Handle y_test shape based on configuration\n",
    "if len(y_test.shape) > 1 and y_test.shape[1] > 1:\n",
    "    print(f\"Multi-step target shape: {y_test.shape}\")\n",
    "    if M_DAYS > 1:\n",
    "        print(f\"Using mean of {M_DAYS}-day prediction period\")\n",
    "    y_test = np.mean(y_test, axis=1)\n",
    "elif len(y_test.shape) > 1:\n",
    "    y_test = y_test.squeeze()\n",
    "\n",
    "print(f\"\\nTest data shapes for {CONFIG_NAME}:\")\n",
    "print(f\"X_test: {X_test.shape} (samples, timesteps, features)\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(f\"Input sequence length: {X_test.shape[1]} timesteps ({X_test.shape[1]/96:.1f} days)\")\n",
    "print(f\"Features per timestep: {X_test.shape[2]}\")\n",
    "\n",
    "# Predictions\n",
    "print(f\"\\nGenerating predictions for {len(X_test)} samples...\")\n",
    "y_pred = model.predict(X_test, verbose=0).squeeze()\n",
    "\n",
    "print(f\"Predictions shape: {y_pred.shape}\")\n",
    "print(f\"Prediction range: [{y_pred.min():.3f}, {y_pred.max():.3f}]\")\n",
    "print(f\"Actual range: [{y_test.min():.3f}, {y_test.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual with configuration-specific analysis\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "fig.suptitle(f'LSTM Performance - {CONFIG_NAME} ({DESCRIPTION})', fontsize=16)\n",
    "\n",
    "# Time series plot (first 1000 points)\n",
    "n_points = min(1000, len(y_test))\n",
    "axes[0].plot(datetime_test['datetime'][:n_points], y_test[:n_points], 'b-', label='Actual', alpha=0.7, linewidth=1)\n",
    "axes[0].plot(datetime_test['datetime'][:n_points], y_pred[:n_points], 'r-', label='Predicted', alpha=0.7, linewidth=1)\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Water Level (m)')\n",
    "axes[0].set_title(f'Time Series: Actual vs Predicted (First {n_points} points)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add performance metrics to time series plot\n",
    "axes[0].text(0.02, 0.98, f'RMSE: {rmse:.4f}m\\nR¬≤: {r2:.4f}\\nInput: {N_DAYS}d‚Üí{M_DAYS}d', \n",
    "            transform=axes[0].transAxes, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Scatter plot\n",
    "axes[1].scatter(y_test, y_pred, alpha=0.5, s=1)\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1].set_xlabel('Actual Water Level (m)')\n",
    "axes[1].set_ylabel('Predicted Water Level (m)')\n",
    "axes[1].set_title(f'Scatter Plot: Actual vs Predicted')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add R¬≤ annotation with configuration info\n",
    "axes[1].text(0.05, 0.95, f'R¬≤ = {r2:.4f}\\nRMSE = {rmse:.4f}m\\n{N_DAYS}d ‚Üí {M_DAYS}d', \n",
    "            transform=axes[1].transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residuals analysis\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(f'Residuals Analysis - {CONFIG_NAME} LSTM', fontsize=16)\n",
    "\n",
    "# Residuals histogram\n",
    "axes[0].hist(residuals, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(residuals.mean(), color='red', linestyle='--', label=f'Mean: {residuals.mean():.4f}')\n",
    "axes[0].set_xlabel('Residuals (m)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title(f'Residuals Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals vs predicted\n",
    "axes[1].scatter(y_pred, residuals, alpha=0.5, s=1)\n",
    "axes[1].axhline(y=0, color='red', linestyle='--')\n",
    "axes[1].set_xlabel('Predicted Values (m)')\n",
    "axes[1].set_ylabel('Residuals (m)')\n",
    "axes[1].set_title('Residuals vs Predicted Values')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== RESIDUALS ANALYSIS - {CONFIG_NAME} ===\")\n",
    "print(f\"Configuration: {DESCRIPTION}\")\n",
    "print(f\"Mean residual: {residuals.mean():.6f} m\")\n",
    "print(f\"Std residual: {residuals.std():.6f} m\")\n",
    "print(f\"Min residual: {residuals.min():.6f} m\")\n",
    "print(f\"Max residual: {residuals.max():.6f} m\")\n",
    "print(f\"95% of errors within: ¬±{np.percentile(np.abs(residuals), 95):.4f} m\")\n",
    "\n",
    "# Configuration-specific residual insights\n",
    "if abs(residuals.mean()) < 0.001:\n",
    "    print(f\"‚úÖ Unbiased LSTM predictions (mean residual ‚âà 0)\")\n",
    "else:\n",
    "    bias_direction = \"over-predicting\" if residuals.mean() < 0 else \"under-predicting\"\n",
    "    print(f\"‚ö†Ô∏è LSTM bias detected: {bias_direction} by {abs(residuals.mean()):.4f}m on average\")\n",
    "\n",
    "# Compare with configuration complexity\n",
    "if timesteps > 1000 and r2 > 0.85:\n",
    "    print(f\"‚úÖ LSTM handles long sequences ({timesteps}) very well\")\n",
    "elif timesteps > 1000 and r2 < 0.75:\n",
    "    print(f\"‚ö†Ô∏è LSTM struggles with very long sequences ({timesteps})\")\n",
    "    print(f\"  Consider reducing sequence length or using attention mechanisms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch m·ªôt v√†i sequences c·ª• th·ªÉ cho configuration\n",
    "sample_indices = [0, len(X_test)//4, len(X_test)//2, len(X_test)*3//4]\n",
    "feature_names = ['Can Tho Rainfall', 'Can Tho Water Level', 'Chau Doc Rainfall', \n",
    "                'Chau Doc Water Level', 'Dai Ngai Rainfall', 'Dai Ngai Water Level']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "fig.suptitle(f'Input Sequences Analysis - {CONFIG_NAME} ({DESCRIPTION})', fontsize=16)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    if idx < len(X_test):\n",
    "        # Plot water level features only (more relevant)\n",
    "        for feat_idx, feat_name in enumerate(feature_names):\n",
    "            if 'Water Level' in feat_name:\n",
    "                # Sample every 10th point for long sequences to avoid overcrowding\n",
    "                if timesteps > 1000:\n",
    "                    step = max(1, timesteps // 100)\n",
    "                    x_seq = X_test[idx, ::step, feat_idx]\n",
    "                    x_axis = np.arange(0, timesteps, step)\n",
    "                else:\n",
    "                    x_seq = X_test[idx, :, feat_idx]\n",
    "                    x_axis = np.arange(timesteps)\n",
    "                    \n",
    "                axes[i].plot(x_axis, x_seq, label=feat_name, linewidth=1.5)\n",
    "        \n",
    "        axes[i].axhline(y=y_test[idx], color='blue', linestyle='--', linewidth=2, \n",
    "                       label=f'Actual: {y_test[idx]:.3f}')\n",
    "        axes[i].axhline(y=y_pred[idx], color='red', linestyle='--', linewidth=2, \n",
    "                       label=f'Predicted: {y_pred[idx]:.3f}')\n",
    "        \n",
    "        error = abs(y_test[idx] - y_pred[idx])\n",
    "        axes[i].set_title(f'Sample {idx}: Error = {error:.4f}m\\n({N_DAYS}d input ‚Üí {M_DAYS}d prediction)')\n",
    "        axes[i].set_xlabel(f'Timestep (15-min intervals, {timesteps} total)')\n",
    "        axes[i].set_ylabel('Normalized Water Level')\n",
    "        axes[i].legend(fontsize=8)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sequence complexity analysis\n",
    "print(f\"\\nüîç Sequence Analysis for {CONFIG_NAME}:\")\n",
    "print(f\"Input sequence length: {timesteps} timesteps ({N_DAYS} days)\")\n",
    "print(f\"Features per timestep: {features_per_interval}\")\n",
    "print(f\"Total input data points: {timesteps * features_per_interval:,}\")\n",
    "\n",
    "if timesteps > 2000:\n",
    "    print(f\"‚ö†Ô∏è  Very long sequences may cause:\")\n",
    "    print(f\"  - Memory issues during training\")\n",
    "    print(f\"  - Vanishing gradient problems\")\n",
    "    print(f\"  - Slower training and inference\")\n",
    "elif timesteps > 500:\n",
    "    print(f\"‚úÖ Long sequences good for:\")\n",
    "    print(f\"  - Capturing seasonal patterns\")\n",
    "    print(f\"  - Long-term dependencies\")\n",
    "else:\n",
    "    print(f\"‚úÖ Short sequences efficient for:\")\n",
    "    print(f\"  - Fast training and inference\")\n",
    "    print(f\"  - Recent pattern focus\")\n",
    "\n",
    "# Analyze prediction difficulty by configuration\n",
    "prediction_difficulty = {\n",
    "    1: \"Easy (short-term)\",\n",
    "    7: \"Medium (weekly)\", \n",
    "    30: \"Hard (monthly)\"\n",
    "}\n",
    "\n",
    "difficulty = prediction_difficulty.get(M_DAYS, f\"Very Hard ({M_DAYS} days)\")\n",
    "print(f\"\\nPrediction difficulty: {difficulty}\")\n",
    "print(f\"LSTM performance: {'Excellent' if r2 > 0.9 else 'Good' if r2 > 0.8 else 'Acceptable' if r2 > 0.7 else 'Needs improvement'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K·∫øt lu·∫≠n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"K·∫æT LU·∫¨N - {CONFIG_NAME} LSTM MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüéØ Configuration: {DESCRIPTION}\")\n",
    "print(f\"üß† Model Type: {MODEL_TYPE} (Recurrent Neural Network)\")\n",
    "print(f\"‚è±Ô∏è Training Time: {training_time/60:.1f} minutes\")\n",
    "print(f\"üé≤ Random Seed: {RANDOM_SEED} (reproducible)\")\n",
    "\n",
    "print(f\"\\nüìà Performance Metrics:\")\n",
    "print(f\"  Test RMSE: {results['test_metrics']['RMSE']:.6f} m (¬±{results['test_metrics']['RMSE']*100:.2f} cm)\")\n",
    "print(f\"  Test MAE:  {results['test_metrics']['MAE']:.6f} m (¬±{results['test_metrics']['MAE']*100:.2f} cm)\")\n",
    "print(f\"  Test R¬≤:   {results['test_metrics']['R2']:.6f} ({results['test_metrics']['R2']*100:.2f}% variance explained)\")\n",
    "print(f\"  Validation Loss: {results['best_val_loss']:.6f}\")\n",
    "print(f\"  Assessment: {performance}\")\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Architecture:\")\n",
    "print(f\"  LSTM Units: {results['best_params']['units']}\")\n",
    "print(f\"  LSTM Layers: {results['best_params']['n_layers']}\")\n",
    "print(f\"  Dropout Rate: {results['best_params']['dropout']}\")\n",
    "print(f\"  Batch Size: {results['best_params']['batch_size']}\")\n",
    "print(f\"  Total Parameters: {results['model_params']['total_params']:,}\")\n",
    "print(f\"  Training Epochs: {results['training_epochs']}/{LSTM_PARAMS['epochs']}\")\n",
    "\n",
    "print(f\"\\nüéØ Sequence Characteristics:\")\n",
    "print(f\"  Input Shape: ({results['data_shapes']['X_test'][0]:,}, {timesteps}, {features_per_interval})\")\n",
    "print(f\"  Sequence Length: {timesteps} timesteps ({N_DAYS} days)\")\n",
    "print(f\"  Prediction Horizon: {M_DAYS} day{'s' if M_DAYS > 1 else ''}\")\n",
    "print(f\"  Training Samples: {results['data_shapes']['X_train'][0]:,}\")\n",
    "print(f\"  Test Samples: {results['data_shapes']['X_test'][0]:,}\")\n",
    "\n",
    "print(f\"\\nüîç Key Insights for {CONFIG_NAME}:\")\n",
    "\n",
    "# Temporal pattern insights\n",
    "if N_DAYS >= 365:\n",
    "    print(f\"  ‚úÖ Captures full seasonal cycles ({N_DAYS} days input)\")\n",
    "elif N_DAYS >= 30:\n",
    "    print(f\"  ‚úÖ Captures monthly patterns ({N_DAYS} days input)\")\n",
    "else:\n",
    "    print(f\"  ‚úÖ Focuses on recent patterns ({N_DAYS} days input)\")\n",
    "\n",
    "# Prediction horizon insights\n",
    "if M_DAYS == 1:\n",
    "    print(f\"  üéØ Short-term prediction: {'Excellent LSTM performance' if r2 > 0.9 else 'Good LSTM performance' if r2 > 0.8 else 'Acceptable performance'}\")\n",
    "elif M_DAYS <= 7:\n",
    "    print(f\"  üéØ Medium-term prediction: {'Impressive LSTM capability' if r2 > 0.8 else 'Reasonable LSTM performance' if r2 > 0.7 else 'Challenging prediction'}\")\n",
    "else:\n",
    "    print(f\"  üéØ Long-term prediction: {'Outstanding LSTM performance' if r2 > 0.7 else 'Acceptable given difficulty' if r2 > 0.6 else 'Difficult prediction task'}\")\n",
    "\n",
    "# Architecture insights\n",
    "if results['best_params']['n_layers'] > 1:\n",
    "    print(f\"  üèóÔ∏è Deep LSTM architecture captures hierarchical temporal patterns\")\n",
    "else:\n",
    "    print(f\"  üèóÔ∏è Single LSTM layer sufficient for this configuration\")\n",
    "\n",
    "if timesteps > 1500:\n",
    "    print(f\"  ‚ö†Ô∏è Very long sequences ({timesteps}) - consider computational efficiency\")\n",
    "elif timesteps > 500:\n",
    "    print(f\"  ‚úÖ Long sequences ({timesteps}) good for capturing patterns\")\n",
    "else:\n",
    "    print(f\"  ‚úÖ Efficient sequence length ({timesteps}) for fast processing\")\n",
    "\n",
    "print(f\"\\nüìÅ Saved Files:\")\n",
    "print(f\"  Model: ../models/{CONFIG_NAME}_lstm/best_model.h5\")\n",
    "print(f\"  Results: ../models/{CONFIG_NAME}_lstm/results.json\")\n",
    "print(f\"  Grid Search: ../models/{CONFIG_NAME}_lstm/grid_search_results.csv\")\n",
    "print(f\"  Training History: ../models/{CONFIG_NAME}_lstm/training_history.csv\")\n",
    "\n",
    "print(f\"\\nüöÄ Production Readiness:\")\n",
    "if r2 > 0.85 and abs(residuals.mean()) < 0.01:\n",
    "    print(f\"  ‚úÖ LSTM model ready for production deployment\")\n",
    "    print(f\"  ‚úÖ Excellent sequential pattern recognition\")\n",
    "    print(f\"  ‚úÖ Unbiased predictions with good accuracy\")\n",
    "elif r2 > 0.75:\n",
    "    print(f\"  ‚ö†Ô∏è LSTM model acceptable but monitor performance\")\n",
    "    print(f\"  üí° Consider ensemble with XGBoost for robustness\")\n",
    "else:\n",
    "    print(f\"  ‚ùå LSTM model needs improvement before production\")\n",
    "    print(f\"  üîß Consider architecture changes or different sequence length\")\n",
    "\n",
    "print(f\"\\nüí° LSTM-Specific Advantages for {CONFIG_NAME}:\")\n",
    "print(f\"  ‚úÖ Captures temporal dependencies naturally\")\n",
    "print(f\"  ‚úÖ Handles variable-length patterns\")\n",
    "print(f\"  ‚úÖ Memory of past states for context\")\n",
    "print(f\"  ‚úÖ Good for non-linear temporal relationships\")\n",
    "\n",
    "print(f\"\\nüîÑ Next Steps:\")\n",
    "print(f\"  1. Compare with XGBoost model for {CONFIG_NAME}\")\n",
    "print(f\"  2. Analyze which approach works better for {N_DAYS}‚Üí{M_DAYS}\")\n",
    "print(f\"  3. Consider ensemble combining both approaches\")\n",
    "print(f\"  4. Test on different seasonal periods\")\n",
    "\n",
    "print(f\"\\n‚úÖ {CONFIG_NAME} LSTM training completed successfully!\")\n",
    "print(f\"üß† Sequential model ready for time series prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
